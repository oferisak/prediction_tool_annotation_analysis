---
title: "Prediction tools analysis"
author: "Ofer Isakov"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: united
    toc: true
    toc_float: false
params:
  all_founder_vars_annotated_file: ''
  clinvar_am_annotated_file: ''
---

# TODO : 
## optional test sets
https://genomeinterpretation.org/cagi6-invitae.html - registered waiting for confirmation

## reviews
golden helix review - https://www.goldenhelix.com/blog/evaluating-deepminds-alphamissense-classifier/
review - https://www.frontiersin.org/articles/10.3389/fgene.2022.1010327/full
check the performance of each tool on benign vs pathogenic (maybe benign variants were used in training ans should be replaced)
benchmarking using deep mutational scans - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10407742/
becnchmarking analysis - phenotype based - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9313608/#humu24362-sec-0020title

```{r markdown_setup,include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd('/media/SSD/Bioinformatics/Projects/prediction_tool_annotation_analysis/')
library(ProjectTemplate)
load.project()

data_folder_name<-'./data/preprocessed_data/2024-01-17'
analysis_folder_name<-glue('./output/prediction_tools_analysis.{Sys.Date()}')
if (!dir.exists(analysis_folder_name)){dir.create(analysis_folder_name)}
```

```{r load_preprocessed_data}
# The annotated table
proc_data_file<-grep('processed_data.prediction_tool_annotation',list.files(data_folder_name,full.names = T),value=T)
proc_data<-readr::read_delim(proc_data_file,delim='\t')
# The var sets to analyze
load(glue('{data_folder_name}/var_sets.RData'))
# Load the ROC data (large, takes time) 
# procs - the ROC curves produced for each var set
# roc_metrics_table - row for each var set, with the AUC and the confidence interval
load(glue('{data_folder_name}/roc_data.RData'))

excluded_tools<-c('esm1b')
tools_to_test<-roc_metrics_table%>%filter(!is.na(TP))%>%pull(tool)%>%unique()
tools_to_test<-grep(paste0(excluded_tools,collapse='|'),tools_to_test,value = T,invert = T)
```

# Variant assertion by year added to clinvar
metrics to test options  - AUC , Accuracy, Balanced accuracy
since we are intereseted in the intra-tool variance, then we should use the entire dataset for each tool

```{r perfo_by_time}
library(ggtext)
perf_metric<-'accuracy'
performance_by_time_table<-
  roc_metrics_table%>%
  filter(sub_var_set=='all',missing_option=='full')%>%
  filter(tool %in% tools_to_test)%>%
  select(tool,main_var_set,perf_metric)%>%pivot_wider(names_from = main_var_set,values_from = perf_metric)%>%
  rowwise()%>%
  mutate(tool=toupper(stringr::str_replace_all(tool,'_score.+','')),
         sd=sd(c(confident_all,confident_2020,confident_2022)),
         diff_2020_all=confident_2020-confident_all,
         diff_2022_all=confident_2022-confident_all,
         diff_2022_2020=confident_2022-confident_2020,)%>%
  group_by(tool)%>%
  mutate(max_2020_all=max(confident_2020,confident_all),
         max_2022_all=max(confident_2022,confident_all),
         max_2022_2020=max(confident_2022,confident_2020))%>%ungroup()%>%
  filter(!is.na(confident_all),!grepl(paste0(excluded_tools,collapse = '|'),tool))
write.table(performance_by_time_table,file=glue('{analysis_folder_name}/performance_by_time_table.{Sys.Date()}.csv'),row.names = F,sep='\t')

# plot the difference between 2022 and the entire dataset
nudge_value<-0.02
years_grid<-combn(c('all','2020','2022'),m = 2,simplify = T)
for (i in 1:ncol(years_grid)){
  comb<-years_grid[,i]
  diff_var<-glue('diff_{comb[2]}_{comb[1]}')
  print(diff_var)
  max_var<-glue('max_{comb[2]}_{comb[1]}')
  to_plot<- performance_by_time_table%>%
    select(tool,max_var,diff_var,glue('confident_{comb[2]}'),glue('confident_{comb[1]}'))%>%
    pivot_longer(-c(tool,max_var,diff_var))%>%
    mutate(name=stringr::str_replace_all(name,'confident_',''),
           tool=forcats::fct_reorder(tool, value))
  performance_by_time_plot<-
  to_plot%>%
    ggplot(aes(x=value,y=tool,label=round(value,3))) +
    geom_line(aes(group=tool,color=ifelse(!!sym(diff_var)>0,comb[2],comb[1])),alpha=0.2, linewidth=3.5) + 
    geom_point(aes(color=name), size=3) +
    geom_text(aes(color=name),
              size=3,
              nudge_x=if_else(
                to_plot$value==to_plot%>%pull(max_var), # if it's the larger value...
                nudge_value,   # move it to the right of the point
                -nudge_value))+
    theme_minimal() +
    theme(legend.position = "top",
          axis.text.y = element_text(color="black"),
          axis.text.x = element_text(color="#989898"),
          axis.title.y = element_blank(),
          panel.grid = element_blank(),plot.title = element_markdown(hjust = 0.5))+
    labs(color='',
         x=stringr::str_to_title(perf_metric),
         title = glue("<span style = 'color: #BF2F24;'>{comb[2]}</span> vs <span style = 'color: #436685;'>{comb[1]}</span>",.comment = '$'))+
    guides(fill='none',color='none')+
    scale_color_manual(values=c("#436685", "#BF2F24"),labels=c(comb[1],comb[2]))
  print(performance_by_time_plot)
  ggsave(filename = glue('{analysis_folder_name}/performance_by_time_{diff_var}_plot.{Sys.Date()}.png'),
         plot=performance_by_time_plot,
         device = 'png',
         height = 10,
         width = 6,
         dpi = 300,bg='white')
}

# by Date


```

# Top models 
collect the top models according to the median AUC

```{r rocs}
# Definitions
selected_main_var_set<-'confident_2020'
selected_sub_var_set<-'all'
selected_missing_option<-'no_missing'
top_num<-10

# collect the corresponding dataset
rocs_data<-procs[[selected_main_var_set]][[selected_sub_var_set]][[selected_missing_option]]
aucs<-roc_metrics_table%>%
  filter(main_var_set==selected_main_var_set,sub_var_set==selected_sub_var_set,missing_option==selected_missing_option)%>%
  filter(tool %in% tools_to_test)%>%
  filter(!is.na(TP))
write.table(aucs,file=glue('{analysis_folder_name}/aucs_table.{Sys.Date()}.csv'),row.names = F,sep='\t')

# Collect the top tools
top_tools<-aucs%>%slice_max(order_by = AUC50.,n=top_num)%>%pull(tool)%>%stringr::str_replace('_score.+','')%>%toupper()

# generate the rocs table
roc_table<-NULL
for (tool in names(rocs_data)){
  roc_table<-roc_table%>%bind_rows(
    data.frame(tool=tool,sensitivity=rocs_data[[tool]]$sensitivities,specificity=rocs_data[[tool]]$specificities)
  )
}
roc_table<-roc_table%>%filter(tool %in% tools_to_test)%>%
  left_join(aucs)%>%
  mutate(tool=stringr::str_replace(tool,'_score.+','')%>%toupper(),
         top_tools=ifelse(tool%in%top_tools,tool,'Other'),
         top_tools=forcats::fct_reorder(top_tools,AUC50.))

colors <- setNames(ggsci::pal_d3()(top_num), top_tools)
colors["Other"] <- "lightgray" 

# Plot the ROC for all the tools and emphasize the top ones
top_models_roc_plot<-
  roc_table%>%
  ggplot(aes(x=1-specificity,y=sensitivity,color=factor(top_tools),group=tool))+
  geom_line(linewidth=1)+
  geom_abline(slope = 1,intercept = 0,linetype=2,alpha=0.4)+
  theme_minimal()+
  theme(legend.position = 'top')+
  scale_color_manual(values=colors)+
  labs(color=NULL)
top_models_roc_plot
ggsave(filename = glue('{analysis_folder_name}/top_models_roc_plot.{Sys.Date()}.png'),
       plot=top_models_roc_plot,
       device = 'png',
       height = 7,
       width = 7,
       dpi = 300,bg='white')

```

# AM vs REVEL

```{r am_vs_revel}
tools_to_plot<-c('alphamissense_score.dbnsfp4.5a','revel_score.dbnsfp4.5a')

# performance - AM versus REVEL  
tools_to_plot<-c('alphamissense_score.dbnsfp4.5a','revel_score.dbnsfp4.5a')
hist_all<-plot_hist_by_class(proc_data[main_var_sets$confident_2020 & sub_var_sets$all & missing_var_sets$full,],
                             tools_to_plot = tools_to_plot,title='All')
hist_all
ggsave(filename = glue('{analysis_folder_name}/am_vs_revel_hist_all_plot.{Sys.Date()}.png'),
       plot=hist_all,
       device = 'png',
       height = 8,
       width = 8,
       dpi = 300,bg='white')
hist_ad<-plot_hist_by_class(proc_data[main_var_sets$confident_2020 & sub_var_sets$AD & missing_var_sets$full,],
                            tools_to_plot = tools_to_plot,title='AD')
hist_ad
ggsave(filename = glue('{analysis_folder_name}/am_vs_revel_hist_ad_plot.{Sys.Date()}.png'),
       plot=hist_ad,
       device = 'png',
       height = 8,
       width = 8,
       dpi = 300,bg='white')
hist_ar<-plot_hist_by_class(proc_data[main_var_sets$confident_2020 & sub_var_sets$AR & missing_var_sets$full,],
                            tools_to_plot = tools_to_plot,title='AR')
hist_ar
ggsave(filename = glue('{analysis_folder_name}/am_vs_revel_hist_ar_plot.{Sys.Date()}.png'),
       plot=hist_ar,
       device = 'png',
       height = 8,
       width = 8,
       dpi = 300,bg='white')
am_vs_revel_hist_plot<-wrap_plots((hist_all+labs(x=NULL,y=NULL)),(hist_ad+guides(fill='none')),(hist_ar+labs(y=NULL,fill=NULL)+guides(fill='none')),nrow=3)
ggsave(filename = glue('{analysis_folder_name}/am_vs_revel_hist_plot.{Sys.Date()}.png'),
       plot=am_vs_revel_hist_plot,
       device = 'png',
       height = 10,
       width = 6,
       dpi = 300,bg='white')


to_plot<-proc_data %>%
  mutate(moi = case_when(
    sub_var_sets[['AD']] == TRUE ~ "AD",
    sub_var_sets[['AR']] == TRUE ~ "AR",
    TRUE ~ NA_character_  # This line handles cases where none of the conditions above are met
  ))%>%
  filter(main_var_sets$confident_2020&missing_var_sets$full&!is.na(facet))
plot_calibration(to_plot,
                 tools_to_plot = tools_to_plot,
                 facet='moi',
                 balanced = T,text_size=18)


```

# Affect of conservation

```{r conservation}
performance_by_conservation_table<-
  roc_metrics_table%>%
  filter(tool %in% tools_to_test)%>%
  filter(grepl('conserv',sub_var_set))%>%
  filter(main_var_set=='confident_all',missing_option=='full')%>%
  mutate(tool=stringr::str_replace(tool,'_score.+','')%>%toupper())%>%
  mutate(tool=forcats::fct_reorder(tool,AUC50.),
         sub_var_set=stringr::str_replace(sub_var_set,'_conservation','')%>%stringr::str_to_title())%>%
  select(main_var_set,sub_var_set,missing_option,tool,total,AUC50.,sens,spec)
write.table(performance_by_conservation_table,file=glue('{analysis_folder_name}/performance_by_conservation_table.{Sys.Date()}.csv'),row.names = F,sep='\t')

# conservation - performance per cons level
performance_by_conservation_plot<-
  performance_by_conservation_table%>%
  pivot_longer(-c(tool,main_var_set,sub_var_set,missing_option,total))%>%
  mutate(name=forcats::fct_recode(name,AUC='AUC50.',Sensitivity='sens',Specificity='spec'))%>%
  ggplot(aes(x=tool,y=value,color=sub_var_set))+
  geom_point(position=position_dodge(width=0.75),size=2)+
  geom_linerange( aes(x=tool, xmin=tool, ymin=0, ymax=value),position=position_dodge(width=c(0.75)))+
  facet_grid(.~name)+
  coord_flip()+
  scale_color_cosmic()+
  labs(color='Conservation',x=NULL)+
  theme_minimal()+
  theme(legend.position = 'top')
performance_by_conservation_plot
ggsave(filename = glue('{analysis_folder_name}/performance_by_conservation_plot.{Sys.Date()}.png'),
       plot=performance_by_conservation_plot,
       device = 'png',
       height = 8,
       width = 9,
       dpi = 300,bg='white')

# calibration plots
text_size<-10
proc_data <- proc_data %>%
  mutate(conservation_status = case_when(
    sub_var_sets[['low_conservation']] == TRUE ~ "Low",
    sub_var_sets[['intermediate_conservation']] == TRUE ~ "Intermediate",
    sub_var_sets[['high_conservation']] == TRUE ~ "High",
    TRUE ~ NA_character_  # This line handles cases where none of the conditions above are met
  ))


scale_min_max <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

reverse_tools<-c('sift_score.dbnsfp4.5a','fathmm_score.dbnsfp4.5a','provean_score.dbnsfp4.5a','sift4g_score.dbnsfp4.5a')

# data for balance
balanced_sample_size_per_tool<-
  proc_data %>%
  select(tools_to_test, clinvar_class, conservation_status) %>%
  pivot_longer(-c(clinvar_class,conservation_status))%>%
  filter(!(is.na(value)|is.na(conservation_status))) %>%
  group_by(name,conservation_status, clinvar_class)%>%
  count()%>%ungroup()%>%group_by(name,conservation_status)%>%summarize(balanced_n=min(n))


proc_data_conservation <- proc_data%>%
    select(tools_to_test,clinvar_class,conservation_status)%>%
    mutate(across(all_of(reverse_tools), ~ .x * -1))%>%
    mutate(across(all_of(tools_to_test), scale_min_max))%>%
    filter(!is.na(conservation_status))%>%
    pivot_longer(cols=-c(clinvar_class,conservation_status))

balanced_data<-NULL
for (tool in tools_to_test){
  print(tool)
  for (conservation in unique(proc_data_conservation$conservation_status)){
    balanced_data<-balanced_data%>%bind_rows(
      proc_data_conservation%>%filter(name==tool)%>%
      filter(conservation_status==conservation)%>%
      slice_sample(n=balanced_sample_size_per_tool%>%filter(name==tool,conservation_status==conservation)%>%pull(balanced_n)))
  }
}

calibration_by_conservation_plot<-
proc_data_conservation%>%
    #mutate(value_cat=cut(value,breaks=c(seq(0,1,0.05)),labels = seq(0.025,0.975,0.05)))%>%
    mutate(value_cat=cut(value,breaks=c(seq(0,1,0.1)),labels = seq(0.05,0.95,0.1)),
           name=stringr::str_replace(name,'_score.+','')%>%toupper())%>%
    group_by(name,value_cat,conservation_status)%>%
    count(clinvar_class)%>%
    mutate(value_cat=as.numeric(as.character(value_cat)),
           total=sum(n),
           rate=n/sum(n))%>%
    filter(clinvar_class=='P/LP')%>%
    mutate(broom::tidy(binom.test(n,total)))%>%
    ggplot(aes(x=value_cat,y=estimate,color=conservation_status,ymin=conf.low,ymax=conf.high))+
    geom_line()+
    geom_point()+
    facet_wrap(name~.,nrow = 3)+
    geom_errorbar(width=0.01)+
    ggsci::scale_color_cosmic()+
    ylim(0,1)+xlim(0,1)+
    labs(color=NULL,x=NULL,y=NULL)+
    geom_abline(intercept = 0,slope = 1,linetype=2,alpha=0.5)+
    theme_minimal()+
    theme(legend.position='top',text = element_text(size=text_size))
calibration_by_conservation_plot
ggsave(filename = glue('{analysis_folder_name}/calibration_by_conservation_plot.{Sys.Date()}.png'),
       plot=calibration_by_conservation_plot,
       device = 'png',
       height = 7,
       width = 14,
       dpi = 300,bg='white')


```

# MOI analysis

```{r moi}
performance_by_moi_table<-
  roc_metrics_table%>%
  filter(tool %in% tools_to_test)%>%
  filter(main_var_set=='confident_2020',sub_var_set%in%c('AD','AR'),missing_option=='full')%>%
  mutate(tool=stringr::str_replace(tool,'_score.+','')%>%toupper())%>%
  mutate(tool=forcats::fct_reorder(tool,AUC50.))%>%
  select(main_var_set,sub_var_set,missing_option,tool,total,AUC50.,sens,spec)
write.table(performance_by_moi_table,file=glue('{analysis_folder_name}/performance_by_moi_table.{Sys.Date()}.csv'),row.names = F,sep='\t')

# conservation - performance per cons level
performance_by_moi_plot<-
  performance_by_moi_table%>%
  pivot_longer(-c(tool,main_var_set,sub_var_set,missing_option,total))%>%
  mutate(name=forcats::fct_recode(name,AUC='AUC50.',Sensitivity='sens',Specificity='spec'))%>%
  ggplot(aes(x=tool,y=value,color=sub_var_set))+
  geom_point(position=position_dodge(width=0.75),size=2)+
  geom_linerange( aes(x=tool, xmin=tool, ymin=0, ymax=value),position=position_dodge(width=c(0.75)))+
  facet_grid(.~name)+
  coord_flip()+
  scale_color_nejm()+
  labs(color='MOI',x=NULL)+
  theme_minimal()+
  theme(legend.position = 'top')
performance_by_moi_plot
ggsave(filename = glue('{analysis_folder_name}/performance_by_moi_plot.{Sys.Date()}.png'),
       plot=performance_by_moi_plot,
       device = 'png',
       height = 8,
       width = 9,
       dpi = 300,bg='white')

# calibration plots
text_size<-10
proc_data <- proc_data %>%
  mutate(moi_status = case_when(
    sub_var_sets[['AD']] == TRUE ~ "AD",
    sub_var_sets[['AR']] == TRUE ~ "AR",
    TRUE ~ NA_character_  # This line handles cases where none of the conditions above are met
  ))


scale_min_max <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

reverse_tools<-c('sift_score.dbnsfp4.5a','fathmm_score.dbnsfp4.5a','provean_score.dbnsfp4.5a','sift4g_score.dbnsfp4.5a')

calibration_by_moi_plot<-
proc_data%>%
    select(tools_to_test,clinvar_class,moi_status)%>%
    mutate(across(all_of(reverse_tools), ~ .x * -1))%>%
    mutate(across(all_of(tools_to_test), scale_min_max))%>%
    filter(!is.na(moi_status))%>%
    pivot_longer(cols=-c(clinvar_class,moi_status))%>%
    #mutate(value_cat=cut(value,breaks=c(seq(0,1,0.05)),labels = seq(0.025,0.975,0.05)))%>%
    mutate(value_cat=cut(value,breaks=c(seq(0,1,0.1)),labels = seq(0.05,0.95,0.1)),
           name=stringr::str_replace(name,'_score.+','')%>%toupper())%>%
    group_by(name,value_cat,moi_status)%>%
    count(clinvar_class)%>%
    mutate(value_cat=as.numeric(as.character(value_cat)),
           total=sum(n),
           rate=n/sum(n))%>%
    filter(clinvar_class=='P/LP')%>%
    mutate(broom::tidy(binom.test(n,total)))%>%
    ggplot(aes(x=value_cat,y=estimate,color=moi_status,ymin=conf.low,ymax=conf.high))+
    geom_line()+
    geom_point()+
    facet_wrap(name~.,nrow = 3)+
    geom_errorbar(width=0.01)+
    ggsci::scale_color_nejm()+
    ylim(0,1)+xlim(0,1)+
    labs(color=NULL,x=NULL,y=NULL)+
    geom_abline(intercept = 0,slope = 1,linetype=2,alpha=0.5)+
    theme_minimal()+
    theme(legend.position='top',text = element_text(size=text_size))
calibration_by_moi_plot
ggsave(filename = glue('{analysis_folder_name}/calibration_by_conservation_plot.{Sys.Date()}.png'),
       plot=calibration_by_conservation_plot,
       device = 'png',
       height = 7,
       width = 14,
       dpi = 300,bg='white')
```


```{r }
z<-
  roc_metrics_table%>%filter(sub_var_set=='all',missing_option=='no_missing')%>%
  select(tool,main_var_set,bal_accuracy)%>%pivot_wider(names_from = main_var_set,values_from = bal_accuracy)%>%
  rowwise()%>%
  mutate(sd=sd(c(confident_all,confident_2020,confident_2022)),
         diff=confident_all-confident_2020)

proc_data%>%filter(main_var_sets[['confident_2020']],sub_var_sets[['all']])%>%
  select(clinvar_class,contains('_score'))%>%
  pivot_longer(-clinvar_class)%>%
  ggplot(aes(x=value,fill=clinvar_class))+
  geom_histogram(alpha=0.5,position='dodge')+
  facet_wrap(name~.,scales = 'free')+
  scale_fill_manual(values=c('darkcyan','darkred'))+
  theme_minimal()+theme(legend.position = 'top')



# GOF vs LOF
roc_metrics_table%>%
  filter(n>200)%>%
  filter(grepl('AD|AR',sub_var_set))%>%filter(class_balance=='balanced_class')%>%filter(main_var_set=='confident_new')%>%
  ggplot(aes(x=tool,y=`X50.`,color=sub_var_set))+
  geom_point()+
  coord_flip()+
  theme_minimal()


# AD vs AR
roc_metrics_table%>%
  filter(n>200)%>%
  filter(grepl('AD|AR',sub_var_set))%>%filter(class_balance=='balanced_class')%>%filter(main_var_set=='confident_new')%>%
  ggplot(aes(x=tool,y=`X50.`,color=sub_var_set))+
  geom_point()+
  coord_flip()+
  theme_minimal()

# allele freq
roc_metrics_table%>%
  filter(n>50)%>%
  filter(grepl('af_cat',sub_var_set))%>%filter(class_balance=='balanced_class')%>%filter(main_var_set=='confident_new')%>%
  mutate(sub_var_set=forcats::fct_relevel(sub_var_set,"af_cat_NA","af_cat_[0.00e+00,8.24e-06)","af_cat_[8.24e-06,4.91e-05)","af_cat_[4.91e-05,2.60e-04)","[2.60e-04,3.18e-03)","af_cat_[3.18e-03,1.00e+00]"))%>%
  ggplot(aes(x=sub_var_set,y=`X50.`,group=tool))+
  geom_point()+
  geom_line()+
  #coord_flip()+
  theme_minimal()

roc_metrics_table%>%
  filter(n>50)%>%
  filter(grepl('af_cat',sub_var_set))%>%filter(class_balance=='balanced_class')%>%filter(main_var_set=='confident_new')%>%
  ggplot(aes(x=tool,y=`X50.`,color=sub_var_set))+
  geom_point()+
  coord_flip()+
  theme_minimal()


# Grab top performing tools for each category
top_3<-
  roc_metrics_table%>%
  filter(n>1000)%>%
  group_by(main_var_set,sub_var_set,class_balance)%>%
  slice_max(n=3,order_by = `X50.`,with_ties = F)%>%
  mutate(rank=rank(-`X50.`))%>%
  pivot_wider(id_cols = c(main_var_set,sub_var_set,class_balance),names_from = rank,values_from = tool)
  

rocs_table%>%
  ggplot(aes(x=1-specificities,y=sensitivities,color=tool))+
  geom_line(size=1,alpha=0.55)+
  geom_abline(linetype=2,alpha=0.5)+
  #ggsci::scale_color_d3()+
  theme_minimal()+
  labs(color=NULL,x='Sensitivity',y='Specificity',linetype=NULL)+
  theme(legend.position = 'top')
roc_plot

```


```{r am_revel_comp}
proc_data%>%ggplot(aes(x=revel_score.dbnsfp4.5a,y=alphamissense_score.dbnsfp4.5a,col=clinvar_class))+
  geom_point(alpha=0.2)+
  scale_color_manual(values=c('darkcyan','darkred'))+
  theme_minimal()

```

# Prepare data
this section parses the clinvar XML and retrieves for each clinvar entry the date created and updated

```{r parseXML}
library(xml2)
library(purrr)
library(XML)

#file_name<-'/media/SSD/Bioinformatics/Databases/clinvar/clinvar_assertions.xml'
file_name<-'/media/SSD/Bioinformatics/Databases/clinvar/ClinVarFullRelease_00-latest.xml.gz'

output_file<-glue('./output/clinvar_assertions.{Sys.Date()}.csv')
clinvar_file<-file_conn <- file(output_file, open = "w")
current_dates <- new.env()
processNode <- function(name, attrs, ...) {
  if (name == "ReferenceClinVarAssertion") {
    #print(attrs)
    # The dates might be in a different node; adjust as needed
    current_dates$date_created <- attrs["DateCreated"]
    current_dates$date_updated <- attrs["DateLastUpdated"]
    }
  if (name=='MeasureSet' & length(attrs)>1){
    #print(attrs['ID'])
    #print(current_dates$date_created)
    id<-attrs['ID']
    #print(date_created)
    if (!is.na(id)){
      if (!is.null(id) && !is.null(current_dates$date_created) && !is.null(current_dates$date_updated)) {
        #print(glue('{id}: {current_dates$date_created} : {current_dates$date_updated}'))
        write.table(x = data.frame(id = id, date_created = current_dates$date_created, date_updated = current_dates$date_updated),
                    file = file_conn, sep = ",", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)
      }
    }
  }
}

xmlEventParse(file_name, handlers = list(startElement = processNode))
close(file_conn)

#clinvar_vars<-bind_rows(clinvar_vars)
```

